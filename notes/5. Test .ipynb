{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "\n",
    "cuda = torch.device('cpu')\n",
    "frame_size = 10\n",
    "batch_size = 1 # only 1 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "movies = pickle.load(open('../data/infos_pca128.pytorch', 'rb'))\n",
    "infos_web = json.load(open('../data/infos.json')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in movies.keys():\n",
    "    movies[i] = movies[i].to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateRepresentation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StateRepresentation, self).__init__()\n",
    "        self.lin = nn.Sequential(\n",
    "            # 128 - embed size, 1 - rating size\n",
    "            nn.Linear(frame_size * (128 + 1), 256),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, info, ratings):\n",
    "        # raw_size - size of the raw movie info. Constant = 2591\n",
    "        # embed_size - size of an ebedded movie. Constant = 64\n",
    "        # raw -> embed via embeddings module defined above\n",
    "        # input: currently info is batch_size x frame_size x raw_size\n",
    "        # step 1: tramsform info to batch_size x (frame_size * embed_size)\n",
    "        info = info.view(batch_size, frame_size * 128)\n",
    "        # step 2: stack info with ratings. stacked: batch_size x (embed_size + 1)\n",
    "        stacked = torch.cat([info, ratings], 1)\n",
    "        # step 3: apply state represemtation module\n",
    "        state = self.lin(stacked)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        self.state_rep = StateRepresentation()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, num_actions)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, info, rewards):\n",
    "        state = self.state_rep(info, rewards)\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.tanh(self.linear3(x))\n",
    "        return state, x\n",
    "    \n",
    "    def get_action(self, info, rewards):\n",
    "        state, action = self.forward(info, rewards)\n",
    "        return state, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        action = torch.squeeze(action)\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "value_net  = Critic(256, 128, 320).to(cuda)\n",
    "policy_net = Actor(256, 128, 192).to(cuda)\n",
    "value_net.load_state_dict(torch.load(\"../models/value.pt\", map_location='cpu'))\n",
    "policy_net.load_state_dict(torch.load(\"../models/policy.pt\", map_location='cpu'))\n",
    "value_net.eval()\n",
    "policy_net.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_ids = [1732, 172, 370, 1639, 1380, 2054, 471, 2502, 1625, 2001]\n",
    "watched_ratings = torch.tensor([4.0, -3.0, -3.0, 2.0, 3.0, -2.0, 3.0, 1.0, 0.0, -1.0]).to(cuda).unsqueeze(0).float()\n",
    "watched_infos = [movies[i] for i in watched_ids] \n",
    "watched_infos = torch.cat(watched_infos).unsqueeze(0)\n",
    "enc_state, action = policy_net(watched_infos, watched_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9985, -0.9969,  0.9973, -0.9970, -0.9986, -0.9968, -0.9970, -0.9993,\n",
       "         -0.9966, -0.9953, -0.9994, -0.9990, -0.9992, -0.9925, -0.9973, -0.9991,\n",
       "         -0.9986, -0.9967, -0.9962, -0.9967, -0.9971, -0.9966,  0.7486, -0.9983,\n",
       "         -0.9938, -0.9993, -0.9943, -0.9988, -0.9951,  0.9997, -0.9969, -0.9994,\n",
       "          0.9977, -0.9935, -0.9993,  0.9988, -0.9990, -0.9986,  0.9983,  0.5878,\n",
       "         -0.9795, -0.9975,  0.0671, -0.9976, -0.9993, -0.9992, -0.9970, -0.9964,\n",
       "          0.8853, -0.9967, -0.9966, -0.9948, -0.9954,  0.9823, -0.9990,  0.9873,\n",
       "         -0.9997, -0.9993, -0.9930, -0.9982, -0.3362, -0.9938, -0.9922, -0.9955,\n",
       "         -0.9971,  0.9997,  0.9988, -0.9993, -0.9989, -0.9710,  0.9949, -0.9990,\n",
       "         -0.9954,  0.9978, -0.9994, -0.9944, -0.9970, -0.9937, -0.9984,  0.9967,\n",
       "         -0.9955, -0.9990, -0.9992, -0.9989, -0.9993, -0.9974, -0.9963, -0.9993,\n",
       "         -0.9911, -0.9990,  0.9983,  0.9981, -0.9991, -0.9993, -0.9993, -0.9991,\n",
       "         -0.9981, -0.9991, -0.9921, -0.9958, -0.9886, -0.9991, -0.9990, -0.9996,\n",
       "         -0.9946, -0.9988, -0.9948, -0.9971, -0.9850,  0.9981, -0.9983, -0.9992,\n",
       "         -0.9991, -0.9965, -0.9950, -0.9994, -0.9993, -0.9960, -0.9991, -0.9956,\n",
       "         -0.9854,  0.9899, -0.9994, -0.9975, -0.9987, -0.9981, -0.9977, -0.9986]],\n",
       "       grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4915, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7103, -0.3453, -0.3574,  0.6183,  0.7056,  0.1067, -0.4534,  0.5810,\n",
       "         0.9717,  0.1858, -0.3109, -0.9241, -0.6142, -0.6273, -0.9086,  0.2766,\n",
       "        -0.7913,  0.7446,  0.0666,  0.9429,  0.8772,  0.2217, -0.4526,  0.0536,\n",
       "         0.2869,  0.2191, -0.1877,  0.2326, -0.7874,  0.9069, -0.8697, -0.0737,\n",
       "        -0.0590,  0.4975, -0.0768, -0.4887, -0.9594, -0.9082,  0.3597, -0.1192,\n",
       "         0.9349,  0.5017,  0.5420, -0.2545,  0.2974, -0.1908,  0.5963, -0.4214,\n",
       "        -0.6902,  0.2583,  0.5453,  0.4400,  0.2924, -0.2870, -0.0389,  0.0935,\n",
       "         0.3440, -0.0054,  0.9166,  0.4394, -0.1058, -0.1101,  0.7794,  0.6250,\n",
       "         0.9588,  0.8355, -0.9057,  0.4041,  0.0464,  0.7430, -0.5783, -0.1685,\n",
       "         0.2270,  0.1166,  0.9292,  0.4437, -0.5728, -0.6607,  0.4373, -0.4984,\n",
       "         0.2863, -0.4826, -0.2174,  0.0786,  0.3916, -0.1597, -0.2943, -0.1576,\n",
       "         0.0875,  0.4856,  0.1884,  0.1208, -0.7054, -0.7903, -0.0713,  0.5164,\n",
       "        -0.6003, -0.9040,  0.4272,  0.7787, -0.4555,  0.6077, -0.6286,  0.5705,\n",
       "        -0.1886,  0.4339,  0.5970,  0.7268,  0.3054, -0.7374, -0.5325,  0.6538,\n",
       "        -0.0066,  0.8138, -0.0209, -0.4683,  0.7853,  0.3942,  0.6606, -0.5861,\n",
       "        -0.1935,  0.4146, -0.5319,  0.2390, -0.0345,  0.4381, -0.0995,  0.1646])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_action = torch.empty(128).uniform_(-1,1)\n",
    "random_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tensor = torch.stack([movies[i] for i in movies.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe = pd.DataFrame({'min': [m_tensor[:,i].min().item() for i in range(m_tensor.size(1))],\n",
    "           'max': [m_tensor[:,i].max().item() for i in range(m_tensor.size(1))],\n",
    "           'mean': [m_tensor[:,i].mean().item() for i in range(m_tensor.size(1))],\n",
    "           'var': [m_tensor[:,i].var().item() for i in range(m_tensor.size(1))],\n",
    "           'std': [m_tensor[:,i].std().item() for i in range(m_tensor.size(1))],\n",
    "          }, index=[str(i) for i in range(128)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.972694</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.047424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.177242</td>\n",
       "      <td>0.087576</td>\n",
       "      <td>0.295933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.038695</td>\n",
       "      <td>0.309991</td>\n",
       "      <td>0.556769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.436343</td>\n",
       "      <td>0.053681</td>\n",
       "      <td>0.231692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.875045</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.071175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.608863</td>\n",
       "      <td>0.017863</td>\n",
       "      <td>0.133653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.123819</td>\n",
       "      <td>0.025534</td>\n",
       "      <td>0.159793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.205939</td>\n",
       "      <td>0.031093</td>\n",
       "      <td>0.176333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.748352</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.056188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.953102</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.837924</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.041671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.034962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.488665</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>0.117597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.396375</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.069720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.417789</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.062733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.207132</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.103617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.185552</td>\n",
       "      <td>0.044211</td>\n",
       "      <td>0.210264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.024055</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.095881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.099063</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.107056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.210608</td>\n",
       "      <td>0.056717</td>\n",
       "      <td>0.238153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.232209</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.122023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.154907</td>\n",
       "      <td>0.031675</td>\n",
       "      <td>0.177974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.074704</td>\n",
       "      <td>0.062037</td>\n",
       "      <td>0.249072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.069057</td>\n",
       "      <td>0.017828</td>\n",
       "      <td>0.133520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.281600</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.141080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.185173</td>\n",
       "      <td>0.049126</td>\n",
       "      <td>0.221644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.156791</td>\n",
       "      <td>0.054078</td>\n",
       "      <td>0.232546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.255904</td>\n",
       "      <td>0.027363</td>\n",
       "      <td>0.165419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.297713</td>\n",
       "      <td>0.022796</td>\n",
       "      <td>0.150983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.046766</td>\n",
       "      <td>0.216253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.039842</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>0.199847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.174469</td>\n",
       "      <td>0.029569</td>\n",
       "      <td>0.171957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.022976</td>\n",
       "      <td>0.031533</td>\n",
       "      <td>0.177575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.303978</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>0.144712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.036003</td>\n",
       "      <td>0.047265</td>\n",
       "      <td>0.217405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.025374</td>\n",
       "      <td>0.032036</td>\n",
       "      <td>0.178986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.059621</td>\n",
       "      <td>0.026170</td>\n",
       "      <td>0.161773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.114391</td>\n",
       "      <td>0.035875</td>\n",
       "      <td>0.189407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.048791</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.181636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.046378</td>\n",
       "      <td>0.040770</td>\n",
       "      <td>0.201917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.063989</td>\n",
       "      <td>0.044409</td>\n",
       "      <td>0.210735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.043051</td>\n",
       "      <td>0.207488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.036180</td>\n",
       "      <td>0.038673</td>\n",
       "      <td>0.196653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.029107</td>\n",
       "      <td>0.030931</td>\n",
       "      <td>0.175871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.096608</td>\n",
       "      <td>0.021620</td>\n",
       "      <td>0.147037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.018812</td>\n",
       "      <td>0.043697</td>\n",
       "      <td>0.209039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.119747</td>\n",
       "      <td>0.032430</td>\n",
       "      <td>0.180083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.184387</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>0.165084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.113013</td>\n",
       "      <td>0.032650</td>\n",
       "      <td>0.180694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.185708</td>\n",
       "      <td>0.029721</td>\n",
       "      <td>0.172398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.135544</td>\n",
       "      <td>0.021122</td>\n",
       "      <td>0.145333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.154051</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>0.175518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.108531</td>\n",
       "      <td>0.039746</td>\n",
       "      <td>0.199364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.045742</td>\n",
       "      <td>0.044235</td>\n",
       "      <td>0.210321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.150192</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>0.175714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.335590</td>\n",
       "      <td>0.027151</td>\n",
       "      <td>0.164775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.268441</td>\n",
       "      <td>0.027497</td>\n",
       "      <td>0.165823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.150890</td>\n",
       "      <td>0.030084</td>\n",
       "      <td>0.173447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.034386</td>\n",
       "      <td>0.033975</td>\n",
       "      <td>0.184324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.045882</td>\n",
       "      <td>0.019327</td>\n",
       "      <td>0.139020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     min  max      mean       var       std\n",
       "0   -1.0  1.0 -0.972694  0.002249  0.047424\n",
       "1   -1.0  1.0 -0.177242  0.087576  0.295933\n",
       "2   -1.0  1.0 -0.038695  0.309991  0.556769\n",
       "3   -1.0  1.0 -0.436343  0.053681  0.231692\n",
       "4   -1.0  1.0 -0.875045  0.005066  0.071175\n",
       "5   -1.0  1.0 -0.608863  0.017863  0.133653\n",
       "6   -1.0  1.0 -0.123819  0.025534  0.159793\n",
       "7   -1.0  1.0 -0.205939  0.031093  0.176333\n",
       "8   -1.0  1.0 -0.748352  0.003157  0.056188\n",
       "9   -1.0  1.0 -0.953102  0.000331  0.018182\n",
       "10  -1.0  1.0 -0.837924  0.001737  0.041671\n",
       "11  -1.0  1.0 -0.012979  0.001222  0.034962\n",
       "12  -1.0  1.0 -0.488665  0.013829  0.117597\n",
       "13  -1.0  1.0 -0.396375  0.004861  0.069720\n",
       "14  -1.0  1.0 -0.417789  0.003935  0.062733\n",
       "15  -1.0  1.0 -0.207132  0.010736  0.103617\n",
       "16  -1.0  1.0 -0.185552  0.044211  0.210264\n",
       "17  -1.0  1.0 -0.024055  0.009193  0.095881\n",
       "18  -1.0  1.0 -0.099063  0.011461  0.107056\n",
       "19  -1.0  1.0 -0.210608  0.056717  0.238153\n",
       "20  -1.0  1.0 -0.232209  0.014890  0.122023\n",
       "21  -1.0  1.0 -0.154907  0.031675  0.177974\n",
       "22  -1.0  1.0 -0.074704  0.062037  0.249072\n",
       "23  -1.0  1.0 -0.069057  0.017828  0.133520\n",
       "24  -1.0  1.0 -0.281600  0.019904  0.141080\n",
       "25  -1.0  1.0 -0.185173  0.049126  0.221644\n",
       "26  -1.0  1.0 -0.156791  0.054078  0.232546\n",
       "27  -1.0  1.0 -0.255904  0.027363  0.165419\n",
       "28  -1.0  1.0 -0.297713  0.022796  0.150983\n",
       "29  -1.0  1.0 -0.000228  0.046766  0.216253\n",
       "..   ...  ...       ...       ...       ...\n",
       "98  -1.0  1.0 -0.039842  0.039939  0.199847\n",
       "99  -1.0  1.0 -0.174469  0.029569  0.171957\n",
       "100 -1.0  1.0 -0.022976  0.031533  0.177575\n",
       "101 -1.0  1.0 -0.303978  0.020942  0.144712\n",
       "102 -1.0  1.0 -0.036003  0.047265  0.217405\n",
       "103 -1.0  1.0 -0.025374  0.032036  0.178986\n",
       "104 -1.0  1.0 -0.059621  0.026170  0.161773\n",
       "105 -1.0  1.0 -0.114391  0.035875  0.189407\n",
       "106 -1.0  1.0 -0.048791  0.032992  0.181636\n",
       "107 -1.0  1.0 -0.046378  0.040770  0.201917\n",
       "108 -1.0  1.0 -0.063989  0.044409  0.210735\n",
       "109 -1.0  1.0  0.005146  0.043051  0.207488\n",
       "110 -1.0  1.0 -0.036180  0.038673  0.196653\n",
       "111 -1.0  1.0 -0.029107  0.030931  0.175871\n",
       "112 -1.0  1.0 -0.096608  0.021620  0.147037\n",
       "113 -1.0  1.0 -0.018812  0.043697  0.209039\n",
       "114 -1.0  1.0 -0.119747  0.032430  0.180083\n",
       "115 -1.0  1.0 -0.184387  0.027253  0.165084\n",
       "116 -1.0  1.0 -0.113013  0.032650  0.180694\n",
       "117 -1.0  1.0 -0.185708  0.029721  0.172398\n",
       "118 -1.0  1.0 -0.135544  0.021122  0.145333\n",
       "119 -1.0  1.0 -0.154051  0.030806  0.175518\n",
       "120 -1.0  1.0 -0.108531  0.039746  0.199364\n",
       "121 -1.0  1.0 -0.045742  0.044235  0.210321\n",
       "122 -1.0  1.0 -0.150192  0.030875  0.175714\n",
       "123 -1.0  1.0 -0.335590  0.027151  0.164775\n",
       "124 -1.0  1.0 -0.268441  0.027497  0.165823\n",
       "125 -1.0  1.0 -0.150890  0.030084  0.173447\n",
       "126 -1.0  1.0 -0.034386  0.033975  0.184324\n",
       "127 -1.0  1.0 -0.045882  0.019327  0.139020\n",
       "\n",
       "[128 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
